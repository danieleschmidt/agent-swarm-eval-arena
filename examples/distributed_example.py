#!/usr/bin/env python3\n\"\"\"Distributed arena example with Ray.\"\"\"\n\nimport ray\nfrom swarm_arena import SwarmConfig\nfrom swarm_arena.core.agent import CooperativeAgent, CompetitiveAgent\nfrom swarm_arena.distributed import DistributedArena, DistributedConfig\n\n\ndef main():\n    \"\"\"Run distributed swarm arena example.\"\"\"\n    print(\"üöÄ Distributed Swarm Arena Example\")\n    print(\"=\" * 50)\n    \n    # Initialize Ray\n    if not ray.is_initialized():\n        ray.init(ignore_reinit_error=True)\n        print(\"Initialized Ray cluster\")\n    \n    try:\n        # Configure massive swarm\n        config = SwarmConfig(\n            num_agents=1000,\n            arena_size=(2000, 2000),\n            episode_length=1000,\n            resource_spawn_rate=0.08,\n            seed=42\n        )\n        \n        # Configure distributed execution\n        distributed_config = DistributedConfig(\n            num_workers=4,\n            agents_per_worker=250,\n            cpu_per_worker=2,\n            memory_per_worker=1024\n        )\n        \n        print(f\"Configuration:\")\n        print(f\"  Total agents: {config.num_agents}\")\n        print(f\"  Arena size: {config.arena_size}\")\n        print(f\"  Workers: {distributed_config.num_workers}\")\n        print(f\"  Agents per worker: {distributed_config.agents_per_worker}\")\n        \n        # Create distributed arena\n        arena = DistributedArena(config, distributed_config)\n        \n        # Add mixed agent types\n        print(f\"\\nAdding agents:\")\n        arena.add_agents(CooperativeAgent, count=400)\n        print(f\"  - 400 cooperative agents\")\n        \n        arena.add_agents(CompetitiveAgent, count=400)\n        print(f\"  - 400 competitive agents\")\n        \n        arena.add_agents(CooperativeAgent, count=200)  # More cooperative\n        print(f\"  - 200 additional cooperative agents\")\n        \n        # Run distributed simulation\n        print(f\"\\nüèÉ Running distributed simulation...\")\n        results = arena.run(episodes=2, verbose=True)\n        \n        # Analyze results\n        print(f\"\\nüìä Distributed Results:\")\n        print(f\"Mean reward per episode: {results.mean_reward:.3f}\")\n        \n        if results.fairness_index is not None:\n            print(f\"Fairness index: {results.fairness_index:.3f}\")\n        \n        print(f\"Total simulation steps: {results.total_steps}\")\n        print(f\"Episode length: {results.episode_length}\")\n        \n        # Performance analysis\n        print(f\"\\n‚ö° Performance Analysis:\")\n        total_agents = sum(len(stats) for stats in [results.agent_stats])\n        print(f\"Processed {total_agents} agents across {distributed_config.num_workers} workers\")\n        \n        # Resource collection comparison\n        coop_agents = [aid for aid in results.agent_stats.keys() if aid < 600]  # First 600 are cooperative\n        comp_agents = [aid for aid in results.agent_stats.keys() if 600 <= aid < 800]  # Next 200 are competitive\n        \n        if coop_agents and comp_agents:\n            coop_resources = sum(results.agent_stats[aid][\"resources_collected\"] for aid in coop_agents)\n            comp_resources = sum(results.agent_stats[aid][\"resources_collected\"] for aid in comp_agents)\n            \n            print(f\"\\nü§ù Cooperation vs Competition:\")\n            print(f\"Cooperative agents (600): {coop_resources} resources ({coop_resources/600:.2f} per agent)\")\n            print(f\"Competitive agents (200): {comp_resources} resources ({comp_resources/200:.2f} per agent)\")\n            \n            if coop_resources/600 > comp_resources/200:\n                print(\"‚úÖ Cooperative agents performed better!\")\n            else:\n                print(\"üí• Competitive agents performed better!\")\n        \n        # Scenario evaluation example\n        print(f\"\\nüß™ Running scenario evaluation...\")\n        scenarios = [\n            {\"name\": \"resource_scarcity\", \"resource_spawn_rate\": 0.02},\n            {\"name\": \"resource_abundance\", \"resource_spawn_rate\": 0.15}\n        ]\n        \n        scenario_results = arena.evaluate_scenarios(scenarios, metrics=[\"efficiency\", \"fairness\"])\n        \n        for scenario_name, scenario_result in scenario_results.items():\n            print(f\"  {scenario_name}: reward={scenario_result.mean_reward:.3f}\")\n        \n    except Exception as e:\n        print(f\"‚ùå Error in distributed simulation: {str(e)}\")\n        raise\n    \n    finally:\n        # Cleanup\n        try:\n            arena.shutdown()\n            print(\"\\nüßπ Distributed arena shut down\")\n        except:\n            pass\n        \n        if ray.is_initialized():\n            ray.shutdown()\n            print(\"Ray cluster shut down\")\n    \n    print(f\"\\n‚úÖ Distributed simulation complete!\")\n\n\nif __name__ == \"__main__\":\n    main()