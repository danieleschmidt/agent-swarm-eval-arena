"""Tests for monitoring and telemetry components."""\n\nimport pytest\nimport time\nimport threading\nfrom unittest.mock import Mock, patch, MagicMock\nimport json\n\nfrom swarm_arena.monitoring import TelemetryCollector, StreamingServer\nfrom swarm_arena.monitoring.telemetry import TelemetryData\nfrom swarm_arena.utils.monitoring import PerformanceMonitor, PerformanceMetrics, HealthStatus\nfrom swarm_arena import Arena, SwarmConfig\nfrom swarm_arena.core.agent import Agent\nfrom swarm_arena.exceptions import NetworkError\n\n\nclass TestTelemetryData:\n    \"\"\"Test TelemetryData class.\"\"\"\n    \n    def test_default_creation(self):\n        \"\"\"Test default telemetry data creation.\"\"\"\n        data = TelemetryData()\n        \n        assert data.step == 0\n        assert data.fps == 0.0\n        assert data.active_agents == 0\n        assert data.total_agents == 0\n        assert data.resources_available == 0\n        assert data.resources_collected == 0\n        assert data.mean_reward == 0.0\n        assert data.cpu_usage == 0.0\n        assert data.memory_usage == 0.0\n        assert data.custom_metrics == {}\n        assert data.timestamp > 0\n    \n    def test_custom_creation(self):\n        \"\"\"Test custom telemetry data creation.\"\"\"\n        custom_metrics = {\"custom_metric\": 42.0}\n        \n        data = TelemetryData(\n            step=100,\n            fps=60.0,\n            active_agents=50,\n            total_agents=100,\n            mean_reward=1.5,\n            custom_metrics=custom_metrics\n        )\n        \n        assert data.step == 100\n        assert data.fps == 60.0\n        assert data.active_agents == 50\n        assert data.total_agents == 100\n        assert data.mean_reward == 1.5\n        assert data.custom_metrics == custom_metrics\n    \n    def test_to_dict(self):\n        \"\"\"Test conversion to dictionary.\"\"\"\n        data = TelemetryData(step=10, fps=30.0, active_agents=25)\n        data_dict = data.to_dict()\n        \n        assert isinstance(data_dict, dict)\n        assert data_dict[\"step\"] == 10\n        assert data_dict[\"fps\"] == 30.0\n        assert data_dict[\"active_agents\"] == 25\n        assert \"timestamp\" in data_dict\n    \n    def test_to_json(self):\n        \"\"\"Test JSON serialization.\"\"\"\n        data = TelemetryData(step=5, active_agents=10)\n        json_str = data.to_json()\n        \n        assert isinstance(json_str, str)\n        \n        # Parse back to verify\n        parsed = json.loads(json_str)\n        assert parsed[\"step\"] == 5\n        assert parsed[\"active_agents\"] == 10\n\n\nclass TestTelemetryCollector:\n    \"\"\"Test TelemetryCollector class.\"\"\"\n    \n    def test_initialization(self):\n        \"\"\"Test telemetry collector initialization.\"\"\"\n        collector = TelemetryCollector(\n            max_history=1000,\n            collection_interval=0.5,\n            auto_start=False\n        )\n        \n        assert collector.max_history == 1000\n        assert collector.collection_interval == 0.5\n        assert collector.collecting is False\n        assert len(collector.data_history) == 0\n        assert len(collector.callbacks) == 0\n    \n    def test_auto_start(self):\n        \"\"\"Test automatic collection start.\"\"\"\n        collector = TelemetryCollector(auto_start=True)\n        \n        # Give time for thread to start\n        time.sleep(0.1)\n        \n        assert collector.collecting is True\n        assert collector.collection_thread is not None\n        \n        collector.stop_collection()\n    \n    def test_manual_start_stop(self):\n        \"\"\"Test manual collection control.\"\"\"\n        collector = TelemetryCollector(auto_start=False)\n        \n        assert collector.collecting is False\n        \n        collector.start_collection()\n        time.sleep(0.1)\n        \n        assert collector.collecting is True\n        \n        collector.stop_collection()\n        assert collector.collecting is False\n    \n    def test_update_telemetry(self):\n        \"\"\"Test telemetry data updates.\"\"\"\n        collector = TelemetryCollector(auto_start=False)\n        \n        collector.update_telemetry(\n            step=10,\n            fps=45.0,\n            active_agents=20,\n            custom_metric=100.0\n        )\n        \n        data = collector.get_latest_data()\n        assert data.step == 10\n        assert data.fps == 45.0\n        assert data.active_agents == 20\n        assert data.custom_metrics[\"custom_metric\"] == 100.0\n        assert collector.update_count == 1\n    \n    def test_record_arena_state(self):\n        \"\"\"Test recording arena state.\"\"\"\n        collector = TelemetryCollector(auto_start=False)\n        \n        # Create mock arena\n        mock_arena = Mock()\n        mock_arena.current_step = 50\n        \n        # Mock agents\n        mock_agent1 = Mock()\n        mock_agent1.state.alive = True\n        mock_agent2 = Mock()\n        mock_agent2.state.alive = False\n        \n        mock_arena.agents = {0: mock_agent1, 1: mock_agent2}\n        \n        # Mock environment stats\n        mock_arena.environment.get_stats.return_value = {\n            \"active_resources\": 10,\n            \"collected_resources\": 5\n        }\n        \n        # Mock episode rewards\n        mock_arena.episode_rewards = {\n            0: [1.0, 2.0, 1.5],\n            1: [0.5, 1.0]\n        }\n        \n        collector.record_arena_state(mock_arena)\n        \n        data = collector.get_latest_data()\n        assert data.step == 50\n        assert data.active_agents == 1  # Only one alive\n        assert data.total_agents == 2\n        assert data.resources_available == 10\n        assert data.resources_collected == 5\n        assert data.fps > 0  # Should calculate FPS\n    \n    def test_callbacks(self):\n        \"\"\"Test telemetry callbacks.\"\"\"\n        collector = TelemetryCollector(auto_start=False)\n        \n        callback_calls = []\n        \n        def test_callback(data: TelemetryData):\n            callback_calls.append(data.step)\n        \n        collector.add_callback(test_callback)\n        assert len(collector.callbacks) == 1\n        \n        # Start collection to trigger callbacks\n        collector.start_collection()\n        \n        # Update data to trigger callback\n        collector.update_telemetry(step=15)\n        \n        time.sleep(0.2)  # Allow callback to be called\n        \n        collector.stop_collection()\n        \n        # Remove callback\n        collector.remove_callback(test_callback)\n        assert len(collector.callbacks) == 0\n    \n    def test_get_history(self):\n        \"\"\"Test getting telemetry history.\"\"\"\n        collector = TelemetryCollector(auto_start=False)\n        \n        # Add some data points\n        for i in range(5):\n            collector.update_telemetry(step=i)\n            collector.data_history.append(collector.get_latest_data())\n        \n        # Get full history\n        full_history = collector.get_history()\n        assert len(full_history) == 5\n        \n        # Get last N entries\n        recent_history = collector.get_history(last_n=3)\n        assert len(recent_history) == 3\n        assert recent_history[0].step == 2  # Should be steps 2, 3, 4\n    \n    def test_get_statistics(self):\n        \"\"\"Test getting telemetry statistics.\"\"\"\n        collector = TelemetryCollector(auto_start=False)\n        \n        # No data case\n        stats = collector.get_statistics()\n        assert stats[\"status\"] == \"no_data\"\n        \n        # Add some data\n        for i in range(3):\n            collector.update_telemetry(step=i, fps=60.0 - i, mean_reward=i * 0.5)\n            collector.data_history.append(collector.get_latest_data())\n        \n        stats = collector.get_statistics()\n        assert stats[\"data_points\"] == 3\n        assert stats[\"avg_fps\"] > 0\n        assert stats[\"avg_reward\"] > 0\n        assert stats[\"update_count\"] == 3\n    \n    def test_export_data_json(self):\n        \"\"\"Test JSON data export.\"\"\"\n        collector = TelemetryCollector(auto_start=False)\n        \n        # Add test data\n        collector.update_telemetry(step=1, active_agents=10)\n        collector.data_history.append(collector.get_latest_data())\n        \n        collector.update_telemetry(step=2, active_agents=15)\n        collector.data_history.append(collector.get_latest_data())\n        \n        json_export = collector.export_data(\"json\")\n        \n        assert isinstance(json_export, str)\n        data_list = json.loads(json_export)\n        assert len(data_list) == 2\n        assert data_list[0][\"step\"] == 1\n        assert data_list[1][\"step\"] == 2\n    \n    def test_export_data_csv(self):\n        \"\"\"Test CSV data export.\"\"\"\n        collector = TelemetryCollector(auto_start=False)\n        \n        # Add test data\n        collector.update_telemetry(step=1, active_agents=10)\n        collector.data_history.append(collector.get_latest_data())\n        \n        csv_export = collector.export_data(\"csv\")\n        \n        assert isinstance(csv_export, str)\n        lines = csv_export.split('\\n')\n        assert len(lines) >= 2  # Header + data\n        assert \"step\" in lines[0]  # Header should contain field names\n        assert \"1\" in lines[1]  # Data should contain step value\n    \n    def test_export_data_invalid_format(self):\n        \"\"\"Test export with invalid format.\"\"\"\n        collector = TelemetryCollector(auto_start=False)\n        \n        with pytest.raises(ValueError):\n            collector.export_data(\"invalid_format\")\n\n\nclass TestStreamingServerMocked:\n    \"\"\"Test StreamingServer with mocked WebSocket functionality.\"\"\"\n    \n    def test_initialization(self):\n        \"\"\"Test streaming server initialization.\"\"\"\n        collector = TelemetryCollector(auto_start=False)\n        server = StreamingServer(\n            host=\"0.0.0.0\",\n            port=9000,\n            telemetry_collector=collector\n        )\n        \n        assert server.host == \"0.0.0.0\"\n        assert server.port == 9000\n        assert server.telemetry_collector == collector\n        assert server.running is False\n        assert len(server.clients) == 0\n    \n    def test_get_server_stats(self):\n        \"\"\"Test server statistics.\"\"\"\n        collector = TelemetryCollector(auto_start=False)\n        server = StreamingServer(telemetry_collector=collector)\n        \n        stats = server.get_server_stats()\n        \n        assert stats[\"host\"] == \"localhost\"\n        assert stats[\"port\"] == 8765\n        assert stats[\"running\"] is False\n        assert stats[\"active_clients\"] == 0\n        assert stats[\"total_clients_connected\"] == 0\n        assert stats[\"messages_sent\"] == 0\n        assert \"uptime\" in stats\n        assert \"telemetry\" in stats\n    \n    @patch('swarm_arena.monitoring.streaming.websockets')\n    @patch('swarm_arena.monitoring.streaming.asyncio')\n    async def test_handle_client_message_ping(self, mock_asyncio, mock_websockets):\n        \"\"\"Test handling client ping message.\"\"\"\n        server = StreamingServer()\n        mock_websocket = Mock()\n        \n        ping_message = json.dumps({\"type\": \"ping\"})\n        \n        with patch.object(server, 'get_server_stats', return_value={}):\n            await server.handle_client_message(mock_websocket, ping_message)\n        \n        # Should send pong response\n        mock_websocket.send.assert_called_once()\n        sent_data = json.loads(mock_websocket.send.call_args[0][0])\n        assert sent_data[\"type\"] == \"pong\"\n    \n    @patch('swarm_arena.monitoring.streaming.websockets')\n    async def test_handle_client_message_get_stats(self, mock_websockets):\n        \"\"\"Test handling get stats message.\"\"\"\n        server = StreamingServer()\n        mock_websocket = Mock()\n        \n        stats_message = json.dumps({\"type\": \"get_stats\"})\n        \n        with patch.object(server, 'get_server_stats', return_value={\"test\": \"data\"}):\n            await server.handle_client_message(mock_websocket, stats_message)\n        \n        mock_websocket.send.assert_called_once()\n        sent_data = json.loads(mock_websocket.send.call_args[0][0])\n        assert sent_data[\"type\"] == \"stats\"\n        assert sent_data[\"data\"][\"test\"] == \"data\"\n    \n    @patch('swarm_arena.monitoring.streaming.websockets')\n    async def test_handle_client_message_invalid_json(self, mock_websockets):\n        \"\"\"Test handling invalid JSON message.\"\"\"\n        server = StreamingServer()\n        mock_websocket = Mock()\n        \n        invalid_message = \"invalid json {{\"\n        \n        await server.handle_client_message(mock_websocket, invalid_message)\n        \n        mock_websocket.send.assert_called_once()\n        sent_data = json.loads(mock_websocket.send.call_args[0][0])\n        assert sent_data[\"type\"] == \"error\"\n        assert \"Invalid JSON\" in sent_data[\"message\"]\n    \n    async def test_send_telemetry_to_client(self):\n        \"\"\"Test sending telemetry to specific client.\"\"\"\n        server = StreamingServer()\n        mock_websocket = Mock()\n        \n        test_data = TelemetryData(step=10, active_agents=5)\n        \n        await server.send_telemetry_to_client(mock_websocket, test_data)\n        \n        mock_websocket.send.assert_called_once()\n        sent_data = json.loads(mock_websocket.send.call_args[0][0])\n        assert sent_data[\"type\"] == \"telemetry\"\n        assert sent_data[\"data\"][\"step\"] == 10\n        assert sent_data[\"data\"][\"active_agents\"] == 5\n    \n    async def test_broadcast_telemetry(self):\n        \"\"\"Test broadcasting telemetry to all clients.\"\"\"\n        server = StreamingServer()\n        \n        # Add mock clients\n        mock_client1 = Mock()\n        mock_client2 = Mock()\n        server.clients = {mock_client1, mock_client2}\n        \n        test_data = TelemetryData(step=15, fps=60.0)\n        \n        await server.broadcast_telemetry(test_data)\n        \n        # Both clients should receive the message\n        mock_client1.send.assert_called_once()\n        mock_client2.send.assert_called_once()\n        \n        # Verify message content\n        sent_data = json.loads(mock_client1.send.call_args[0][0])\n        assert sent_data[\"type\"] == \"telemetry\"\n        assert sent_data[\"data\"][\"step\"] == 15\n        assert sent_data[\"data\"][\"fps\"] == 60.0\n        \n        assert server.messages_sent == 2\n\n\nclass TestPerformanceMonitor:\n    \"\"\"Test PerformanceMonitor class.\"\"\"\n    \n    def test_initialization(self):\n        \"\"\"Test performance monitor initialization.\"\"\"\n        monitor = PerformanceMonitor(\n            cpu_threshold=80.0,\n            memory_threshold=75.0,\n            min_fps=15.0,\n            max_step_time=0.5\n        )\n        \n        assert monitor.cpu_threshold == 80.0\n        assert monitor.memory_threshold == 75.0\n        assert monitor.min_fps == 15.0\n        assert monitor.max_step_time == 0.5\n        assert monitor.monitoring is False\n        assert len(monitor.metrics_history) == 0\n    \n    @patch('swarm_arena.utils.monitoring.psutil')\n    def test_record_metrics(self, mock_psutil):\n        \"\"\"Test recording performance metrics.\"\"\"\n        # Mock psutil calls\n        mock_psutil.cpu_percent.return_value = 45.0\n        mock_memory_info = Mock()\n        mock_memory_info.percent = 60.0\n        mock_psutil.virtual_memory.return_value = mock_memory_info\n        \n        monitor = PerformanceMonitor()\n        \n        metrics = monitor.record_metrics(\n            fps=30.0,\n            step_time=0.02,\n            agents_active=100,\n            resources_available=50\n        )\n        \n        assert isinstance(metrics, PerformanceMetrics)\n        assert metrics.cpu_usage == 45.0\n        assert metrics.memory_usage == 60.0\n        assert metrics.fps == 30.0\n        assert metrics.step_time == 0.02\n        assert metrics.agents_active == 100\n        assert metrics.resources_available == 50\n        \n        assert len(monitor.metrics_history) == 1\n    \n    def test_check_health_no_data(self):\n        \"\"\"Test health check with no data.\"\"\"\n        monitor = PerformanceMonitor()\n        \n        health = monitor.check_health()\n        \n        assert isinstance(health, HealthStatus)\n        assert health.status == \"warning\"\n        assert \"No metrics available\" in health.warnings\n    \n    def test_check_health_with_data(self):\n        \"\"\"Test health check with performance data.\"\"\"\n        monitor = PerformanceMonitor(\n            cpu_threshold=50.0,\n            memory_threshold=70.0,\n            min_fps=20.0,\n            max_step_time=0.1\n        )\n        \n        # Add mock metrics\n        good_metrics = PerformanceMetrics(\n            cpu_usage=40.0,\n            memory_usage=60.0,\n            fps=30.0,\n            step_time=0.05\n        )\n        monitor.metrics_history.append(good_metrics)\n        \n        health = monitor.check_health()\n        \n        assert health.status == \"healthy\"\n        assert health.cpu_ok is True\n        assert health.memory_ok is True\n        assert health.performance_ok is True\n    \n    def test_check_health_critical_issues(self):\n        \"\"\"Test health check with critical issues.\"\"\"\n        monitor = PerformanceMonitor(\n            cpu_threshold=50.0,\n            memory_threshold=70.0\n        )\n        \n        # Add bad metrics\n        bad_metrics = PerformanceMetrics(\n            cpu_usage=95.0,  # High CPU\n            memory_usage=85.0,  # High memory\n            fps=5.0,  # Low FPS\n            step_time=2.0  # Slow steps\n        )\n        monitor.metrics_history.append(bad_metrics)\n        \n        health = monitor.check_health()\n        \n        assert health.status == \"critical\"\n        assert health.cpu_ok is False\n        assert health.memory_ok is False\n        assert len(health.errors) >= 2  # CPU and memory errors\n    \n    def test_get_performance_summary(self):\n        \"\"\"Test performance summary generation.\"\"\"\n        monitor = PerformanceMonitor()\n        \n        # Add test metrics\n        for i in range(5):\n            metrics = PerformanceMetrics(\n                cpu_usage=50.0 + i,\n                memory_usage=60.0 + i,\n                fps=30.0 - i,\n                step_time=0.01 + i * 0.005\n            )\n            monitor.metrics_history.append(metrics)\n        \n        summary = monitor.get_performance_summary()\n        \n        assert \"avg_cpu_usage\" in summary\n        assert \"avg_memory_usage\" in summary\n        assert \"avg_fps\" in summary\n        assert \"avg_step_time\" in summary\n        assert summary[\"metrics_count\"] == 5\n    \n    def test_start_stop_monitoring(self):\n        \"\"\"Test starting and stopping monitoring.\"\"\"\n        monitor = PerformanceMonitor()\n        \n        assert monitor.monitoring is False\n        \n        monitor.start_monitoring(interval=0.1)\n        time.sleep(0.05)\n        \n        assert monitor.monitoring is True\n        assert monitor.monitor_thread.is_alive()\n        \n        monitor.stop_monitoring()\n        assert monitor.monitoring is False\n    \n    def test_reset_counters(self):\n        \"\"\"Test resetting error counters.\"\"\"\n        monitor = PerformanceMonitor()\n        \n        monitor.error_count = 5\n        monitor.warning_count = 3\n        \n        monitor.reset_counters()\n        \n        assert monitor.error_count == 0\n        assert monitor.warning_count == 0\n\n\nclass TestMonitoringIntegration:\n    \"\"\"Integration tests for monitoring components.\"\"\"\n    \n    def test_telemetry_with_real_arena(self):\n        \"\"\"Test telemetry collection with real arena.\"\"\"\n        config = SwarmConfig(num_agents=5, episode_length=10, seed=42)\n        arena = Arena(config)\n        arena.add_agents(Agent, count=5)\n        \n        collector = TelemetryCollector(auto_start=False)\n        \n        arena.reset()\n        \n        # Run a few steps and collect telemetry\n        for _ in range(3):\n            arena.step()\n            collector.record_arena_state(arena)\n        \n        data = collector.get_latest_data()\n        \n        assert data.step == arena.current_step\n        assert data.total_agents == 5\n        assert data.active_agents <= 5\n        assert data.fps > 0\n    \n    def test_performance_monitoring_with_arena(self):\n        \"\"\"Test performance monitoring with arena execution.\"\"\"\n        config = SwarmConfig(num_agents=3, episode_length=5, seed=42)\n        arena = Arena(config)\n        arena.add_agents(Agent, count=3)\n        \n        monitor = PerformanceMonitor()\n        \n        arena.reset()\n        \n        # Run simulation and record metrics\n        for step in range(3):\n            step_start = time.time()\n            arena.step()\n            step_time = time.time() - step_start\n            \n            monitor.record_metrics(\n                fps=1.0 / step_time if step_time > 0 else 0,\n                step_time=step_time,\n                agents_active=sum(1 for agent in arena.agents.values() if agent.state.alive),\n                resources_available=arena.environment.get_stats().get(\"active_resources\", 0)\n            )\n        \n        # Check that metrics were recorded\n        assert len(monitor.metrics_history) == 3\n        \n        # Check health\n        health = monitor.check_health()\n        assert health.status in [\"healthy\", \"warning\"]  # Should not be critical\n        \n        # Get summary\n        summary = monitor.get_performance_summary()\n        assert summary[\"avg_fps\"] > 0\n        assert summary[\"metrics_count\"] == 3\n    \n    @patch('swarm_arena.monitoring.streaming.create_streaming_server')\n    def test_streaming_server_creation(self, mock_create_server):\n        \"\"\"Test streaming server creation helper.\"\"\"\n        from swarm_arena.monitoring.streaming import create_streaming_server\n        \n        config = SwarmConfig(num_agents=2, seed=42)\n        arena = Arena(config)\n        \n        # Mock the actual function to avoid WebSocket setup\n        mock_server = Mock()\n        mock_create_server.return_value = mock_server\n        \n        server = create_streaming_server(arena, \"localhost\", 8080)\n        \n        mock_create_server.assert_called_once_with(arena, \"localhost\", 8080)\n        assert server == mock_server